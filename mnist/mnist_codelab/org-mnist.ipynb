{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_NODE = 784     # 输入节点\n",
    "OUTPUT_NODE = 10     # 输出节点\n",
    "LAYER1_NODE = 500    # 隐藏层数                        \n",
    "BATCH_SIZE = 100     # 每次batch打包的样本个数        \n",
    "\n",
    "# 模型相关的参数\n",
    "LEARNING_RATE = 0.05      \n",
    "TRAINING_STEPS = 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(input_tensor):\n",
    "    # 生成隐藏层的参数。\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    # 生成输出层的参数。\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "    return tf.matmul(layer1, weights2) + biases2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_graph():\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    # 计算不含滑动平均类的前向传播结果\n",
    "    y = inference(x)\n",
    "    \n",
    "    # 定义训练轮数\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)    \n",
    "    \n",
    "    # 计算交叉熵及其平均值\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # 优化损失函数\n",
    "    train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(\n",
    "        cross_entropy_mean, global_step=global_step)\n",
    "    \n",
    "    # 计算正确率\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return x, y_, train_op, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x, y_, train_op, accuracy, mnist):\n",
    "    # 初始化会话，并开始训练过程。\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    validate_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n",
    "            \n",
    "    # 循环的训练神经网络。\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        if i % 1000 == 0:\n",
    "            validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "            print(\"After %d training step(s), validation accuracy using average model is %g \" % (i, validate_acc))\n",
    "            \n",
    "        xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(train_op,feed_dict={x:xs,y_:ys})\n",
    "    \n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(x, y_, accuracy, mnist, sess):\n",
    "    test_feed = {x: mnist.test.images, y_: mnist.test.labels} \n",
    "    test_acc = sess.run(accuracy,feed_dict=test_feed)\n",
    "    print((\"After %d training step(s), test accuracy using average model is %g\" %(TRAINING_STEPS, test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy using average model is 0.0584 \n",
      "After 1000 training step(s), validation accuracy using average model is 0.936 \n",
      "After 2000 training step(s), validation accuracy using average model is 0.9518 \n",
      "After 3000 training step(s), validation accuracy using average model is 0.958 \n",
      "After 4000 training step(s), validation accuracy using average model is 0.9652 \n",
      "After 5000 training step(s), test accuracy using average model is 0.9639\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "    x, y_, train_op, accuracy = define_graph()\n",
    "    sess = train(x, y_, train_op, accuracy, mnist)\n",
    "    test(x, y_, accuracy, mnist, sess)\n",
    "    sess.close()\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
